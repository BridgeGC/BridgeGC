# BridgeGC
BridgeGC is an efficient semi-automatic garbage collector for big data frameworks such as Flink and Spark. Specially, BridgeGC is built on [OpenJDK 16 HotSpot](https://github.com/openjdk/jdk16) to reduce the GC time spent on long-lived data objects generated by the frameworks. As shown in Figure 1, BridgeGC uses limited manual annotations at the creation/release points of data objects to profile their life cycles, then BridgeGC leverages the life cycles information of annotated data objects to efficiently allocate them in JVM heap and reclaim them without unnecessary marking/copying overhead.
<div align=center>
<img decoding="async" src="Figures/bridgegc-intro.svg" width="50%">

**Figure 1: Comparison between BridgeGC and traditional GC.**
</div>

# Usage

## Build

Download our source code, follow the [instructions](https://openjdk.org/groups/build/doc/building.html) to build the OpenJDK JVM, resulting in a JVM with BridgeGC. 

## Annotations
We provide two simple annotations, `@DataObj` and `System.Reclaim()`, that can be used by the framework developers to annotate the creation and release points of data objects. Specifically, the annotation `@DataObj` is used along with the keyword `new` to denote the creation of data objects. The annotation `System.Reclaim()` is used to denote the release of a batch of data objects. We show how we apply annotations in Spark, Flink and Cassandra briefly as follows and more details can be found [here](Apply/README.md).

<div align=center>
<img decoding="async" src="Figures/flink.svg" width="50%">

**Figure 2: Apply BridgeGC annotations to `MemorySegment`.**
</div>

<div align=center>
<img decoding="async" src="Figures/spark-rdd.svg" width="50%">

**Figure 3: Apply BridgeGC annotations to chunked `ByteBuffer`.**
</div>

<div align=center>
<img decoding="async" src="Figures/spark-tungsten.svg" width="50%">

**Figure 4: Apply BridgeGC annotations to `MemoryBlock`.**
</div>

<div align=center>
<img decoding="async" src="Figures/cassandra.svg" width="50%">

**Figure 5: Apply BridgeGC annotations to `ByteBuffer` for Memtable.**
</div>

## Run
After adding the annotations, compile the framework. Before running the framework, just add `-XX:+UseBridgeGC` to JVM parameters of the executor/server to enable BridgeGC.

# Implementation
We design three components in BridgeGC to efficiently profile, allocate, and reclaim annotated data objects.

## Precise Data Object Profiler
The profiler is designed to identify data objects and track the life cycles of data objects through annotations, it processes `@DataObj` and `System.Reclaim()` annotations at the runtime to inform the garbage collector of allocation and reclaimable time of data objects.

## Memory-Efficient Label-Based Allocator
The allocator separates the storage of data objects and normal objects in data pages and normal pages, and tackles the problem of space balance by dynamic page allocation. To distinguish data objects readily at the GC level, the allocator labels them using colored pointer.

## Effective Marking/Copying-Conservation Collector 
The collector skips marking labeled data objects and excludes data pages from reclamation in GC cycles where data objects are known to be lived, and performs effective reclamation of data pages only after some annotated data objects are released at the framework level.

# Evaluation
We apply and evaluate BridgeGC with Flink 1.9.3 and Spark 3.3.0. We compare BridgeGC with all available garbage collectors in OpenJDK 16, includes ZGC, G1, and Parallel. 
<!-- We also compare BridgeGC with a state-of-the-art research work [ROLP](https://rodrigo-bruno.github.io/papers/rbruno-eurosys19.pdf).-->
## Flink
we select five batch machine learning applications that are memory intensive from [Flink examples](https://github.com/apache/flink/tree/master/flink-exa) as the driving workload, including Linear Regression (LR), KMeans (KM), PageRank (PR), Components (CC) and WebLogAnalysis (WA). We also use the TPC-H benchmark suite from [Flink end-to-end test](https://github.com/apache/flink/tree/master/flink-end-to-end-tests/flink-tpch-test).

Results show that BridgeGC reduces concurrent GC time by 28\%-78\% compared to the baseline ZGC. In terms of application execution time, BridgeGC reduces by 2\%-26\% compared to ZGC, and outperforms other evaluated collectors as shown in Figure 6(a).   
<div align=center>
<img decoding="async" src="Figures/asplos_flink_overall.svg" width="100%">

**Figure 6: Speedup of evaluated collectors compared to ZGC with Flink and Spark Workloads.**
</div>

## Spark
We choose five representative ML applications from popular big data benchmark [HiBench](https://github.com/Intel-bigdata/HiBench), including Linear Regression (LR), Support Vector Machine (SVM), Gaussian Mixture Model (GMM), KMeans (KM), and PageRank (PR). We also execute the entire TPC-H benchmark using SparkSQL.

Results show that BridgeGC reduces concurrent GC time by 19\%-46\% compared to the baseline ZGC. In terms of application execution time, BridgeGC reduces by 2\%-10\% compared to ZGC, and outperforms other evaluated collectors as shown in Figure 6(b).

<div align=center>
<img decoding="async" src="Figures/spark_overall.svg" width="100%">

**Figure 7: Speedup of evaluated collectors compared to ZGC with Spark Applications.**
</div>